{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1INThpNxc-e5GEMpdfQrU9BMOe6UeUdLs","timestamp":1716572919283}],"gpuType":"V100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install torchviz\n","!pip install graphviz\n","!pip install torchview\n","\n","!pip install torchinfo"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sQUeuVEYkSMi","outputId":"b937c580-aeb6-47f1-e8c5-d9a8ce61ffdc","executionInfo":{"status":"ok","timestamp":1714936932371,"user_tz":240,"elapsed":30968,"user":{"displayName":"William Symolon","userId":"08028043712345432423"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchviz in /usr/local/lib/python3.10/dist-packages (0.0.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz) (2.2.1+cu121)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz) (0.20.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->torchviz) (12.4.127)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchviz) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchviz) (1.3.0)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (0.20.3)\n","Requirement already satisfied: torchview in /usr/local/lib/python3.10/dist-packages (0.2.6)\n","Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kE3-IuQKjsCd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714936939162,"user_tz":240,"elapsed":6797,"user":{"displayName":"William Symolon","userId":"08028043712345432423"}},"outputId":"45ac2e78-a5b6-4c1a-fd29-8f59d11e36c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cuda\n"]}],"source":["\n","import os\n","import math\n","import random\n","\n","import cv2\n","import numpy as np\n","import time\n","\n","import matplotlib.pyplot as plt\n","\n","import os\n","from PIL import Image\n","\n","import torch\n","from torch.nn import init\n","from torch import nn, optim\n","from torchinfo import summary\n","from torch.nn import functional as F\n","from torchvision.io import read_image\n","from torch.nn.utils import spectral_norm\n","from torchvision.utils import save_image\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.transforms import functional as TF\n","from torchviz import make_dot\n","from torchview import draw_graph\n","\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","print(f'Device: {device}')"]},{"cell_type":"code","source":["class SRDataset(Dataset):\n","    def __init__(self, path, mode='train'):\n","        if mode == 'train':\n","            self.hr_path = os.path.join(path, 'hr_crop')\n","            self.lr_path = os.path.join(path, 'lr_crop')\n","        elif mode == 'test':\n","            #self.hr_path = os.path.join(path, 'hr')\n","            self.lr_path = os.path.join(path, 'lr')\n","\n","        # Filter to include only .png files\n","        #self.hr_images = [file for file in sorted(os.listdir(self.hr_path)) if file.endswith(('.png', '.jpg', '.jpeg', '.bmp'))]\n","        self.lr_images = [file for file in sorted(os.listdir(self.lr_path)) if file.endswith(('.png', '.jpg', '.jpeg', '.bmp'))]\n","\n","        self.mode = mode\n","\n","    def __len__(self):\n","        return len(self.lr_images)\n","\n","    def __getitem__(self, index):\n","        #hr_image_filename = self.hr_images[index]\n","        lr_image_filename = self.lr_images[index]\n","        #hr_image_path = os.path.join(self.hr_path, hr_image_filename)\n","        lr_image_path = os.path.join(self.lr_path, lr_image_filename)\n","        #hr_image = read_image(hr_image_path) / 255.\n","        lr_image = read_image(lr_image_path) / 255.\n","\n","        if self.mode == 'train':\n","            # Apply random flip augmentation\n","            if random.random() > 0.5:\n","                angle = random.choice([90, 180, 270])\n","                hr_image = TF.rotate(hr_image, angle)\n","                lr_image = TF.rotate(lr_image, angle)\n","\n","            # Apply RGB channel permutation\n","            if random.random() > 0.5:\n","                channels = torch.randperm(3)\n","                hr_image = hr_image[channels]\n","                lr_image = lr_image[channels]\n","\n","        # Rotate lr_image by 1, 2, -1 degrees\n","        lr_added_1 = torch.clamp((lr_image * 255 + 1), max=255) / 255.\n","        lr_rotated_2 = TF.rotate(lr_image, 2)\n","        lr_rotated_neg_1 = TF.rotate(lr_image, -1)\n","\n","        # Concatenate original and rotated images along the channel dimension\n","        lr_image_augmented = torch.cat((lr_image, lr_added_1, lr_rotated_2, lr_rotated_neg_1), dim=0)\n","\n","        #return hr_image, lr_image_augmented\n","        return lr_image_augmented"],"metadata":{"id":"YkRPjiA-jvwI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Pc3z-DTZjxqF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714936939860,"user_tz":240,"elapsed":704,"user":{"displayName":"William Symolon","userId":"08028043712345432423"}},"outputId":"78f1a77a-81b8-4020-d4f5-f0717c4edaaa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["#%cd drive/My\\ Drive/Colab Notebooks/MISR_CNN\n","#!ls"],"metadata":{"id":"m5TY3LSj3htN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 8\n","\n","val_path = '/content/drive/MyDrive//Colab Notebooks/MISR_CNN/Allimages/LRtest_imgs'\n","\n","val_dataset = SRDataset(val_path, mode='test')\n","\n","val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False,\n","                          num_workers=4)"],"metadata":{"id":"9xL5DlwBj1Ue"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def make_layer(basic_block, num_basic_block, **kwargs):\n","    \"\"\"Make layers by stacking the same blocks.\"\"\"\n","    layers = []\n","    for _ in range(num_basic_block):\n","        layers.append(basic_block(**kwargs))\n","    return nn.Sequential(*layers)\n","\n","class DenseBlock(nn.Module):\n","    \"\"\"Dense Block.\"\"\"\n","    def __init__(self, embed_dim=64):\n","        super(DenseBlock, self).__init__()\n","        self.norm = nn.LayerNorm(embed_dim)\n","        self.conv1 = nn.Conv2d(embed_dim, embed_dim, 3, 1, 1)\n","        self.conv2 = nn.Conv2d(embed_dim, embed_dim, 3, 1, 1)\n","        self.conv3 = nn.Conv2d(embed_dim, embed_dim, 3, 1, 1)\n","        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n","\n","    def forward(self, x):\n","        res = x.clone()  # Use clone to avoid modifying the input directly\n","        x = self.norm(x.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n","        x1 = self.lrelu(self.conv1(x))\n","        x2 = self.lrelu(self.conv2(x + x1))\n","        x3 = self.lrelu(self.conv3(x + x1 + x2))\n","        return x3*0.3 + res\n","\n","class RDB(nn.Module):\n","    \"\"\"Residual Dense Block.\"\"\"\n","    def __init__(self, embed_dim):\n","        super(RDB, self).__init__()\n","        self.rdb1 = DenseBlock(embed_dim)\n","        self.rdb2 = DenseBlock(embed_dim)\n","        self.rdb3 = DenseBlock(embed_dim)\n","\n","    def forward(self, x):\n","        out = self.rdb1(x)\n","        out = self.rdb2(out)\n","        out = self.rdb3(out)\n","        return out*0.3+ x\n","\n","class Upsample(nn.Sequential):\n","    \"\"\"Upsample module.\"\"\"\n","    def __init__(self, scale, num_feat):\n","        m = []\n","        if (scale & (scale - 1)) == 0:  # Check if scale is a power of 2\n","            for _ in range(int(math.log(scale, 2))):\n","                m.append(nn.Conv2d(num_feat, 4 * num_feat, 3, 1, 1))\n","                m.append(nn.PixelShuffle(2))\n","        elif scale == 3:\n","            m.append(nn.Conv2d(num_feat, 9 * num_feat, 3, 1, 1))\n","            m.append(nn.PixelShuffle(3))\n","        else:\n","            raise ValueError(f'scale {scale} is not supported. Supported scales: 2^n and 3.')\n","        super(Upsample, self).__init__(*m)\n","\n","class CNN(nn.Module):\n","    \"\"\"\n","    Args:\n","        num_in_ch (int): Channel number of inputs.\n","        num_out_ch (int): Channel number of outputs.\n","        embed_dim (int): Channel number of intermediate features.\n","            Default: 64\n","        num_block (int): Block number in the trunk network. Defaults: 23\n","    \"\"\"\n","\n","    def __init__(self, num_in_ch, num_out_ch, upscale=4, embed_dim=64, num_block=16, num_final_feat=64):\n","        super(CNN, self).__init__()\n","        self.upscale = upscale\n","\n","        # ------------------------- 1, shallow feature extraction ------------------------- #\n","        self.conv_first = nn.Conv2d(num_in_ch, embed_dim, 3, 1, 1)\n","\n","        # ------------------------- 2, deep feature extraction ------------------------- #\n","        self.body = make_layer(RDB, num_block, embed_dim=embed_dim)\n","        self.conv_body = nn.Conv2d(embed_dim, embed_dim, 3, 1, 1)\n","\n","        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n","\n","        # ------------------------- 3, high quality image reconstruction ------------------------- #\n","        self.conv_before_upsample = nn.Sequential(\n","            nn.Conv2d(embed_dim, num_final_feat, 3, 1, 1), nn.LeakyReLU(inplace=True))\n","        self.upsample = Upsample(upscale, num_final_feat)\n","        self.conv_last = nn.Conv2d(num_final_feat, num_out_ch, 3, 1, 1)\n","\n","        self.apply(self._init_weights)\n","\n","    def _init_weights(self, m):\n","        if isinstance(m, nn.LayerNorm):\n","            nn.init.constant_(m.bias, 0)\n","            nn.init.constant_(m.weight, 1.0)\n","\n","    def forward(self, x):\n","        feat = self.conv_first(x)\n","\n","        body_feat = self.conv_body(self.body(feat))\n","        feat = feat + body_feat\n","\n","        # upsample\n","        feat = self.conv_before_upsample(feat)\n","        out = self.conv_last(self.upsample(feat))\n","        return out\n","\n","model = CNN(num_in_ch=12, num_out_ch=3).to(device)\n"],"metadata":{"id":"bDAdNktSj4CE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output_dir = '/content/drive/MyDrive//Colab Notebooks/MISR_CNN/Output/sr_prediction'\n","model_path = '/content/drive/MyDrive//Colab Notebooks/MISR_CNN/models/*.pth' # replace '*' with filename of desired .pth file\n","\n","if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","model.load_state_dict(torch.load(model_path))\n","\n","model.eval()  # Set model to evaluation mode\n","with torch.no_grad():  # No gradients needed\n","    for i, (low_res) in enumerate(val_loader):\n","        low_res = low_res.to(device)\n","        super_res = model(low_res)  # Generate high-resolution output from model\n","\n","        # Saving each image pair: low_res and super_res\n","        save_image(low_res[:, :3].clamp(0, 1), f'{output_dir}/planet_low_res_sample_{i+1}.png', normalize=False)\n","        save_image(super_res.clamp(0, 1), f'{output_dir}/planet_super_res_sample_{i+1}.png', normalize=False)"],"metadata":{"id":"dbgpn8-9JOi9"},"execution_count":null,"outputs":[]}]}